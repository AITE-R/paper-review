# paper-review
Review and implementation of papers

### Reviewed Paper List
- [x] [`LoRA (ICLR 2022)`](https://arxiv.org/abs/2106.09685) `LLM Adapter for efficient fine-tuning`
- [x] [`Attention Is All You Need (NeurIPS 2017)`](https://arxiv.org/abs/1706.03762) `Sequence-to-sequence model with self-attention`